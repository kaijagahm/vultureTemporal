---
title: "temporal"
format: 
  html:
    embed-resources: true
editor: visual
---

```{r}
#| include: false
library(tidyverse) # for data wrangling
library(sf) # for spatial manipulation (necessary as a precursor to getting edgelists)
library(vultureUtils) # for getting edgelists
library(igraph) # for working with networks
library(tidygraph) # for working with networks
library(future) # for parallel processing
library(furrr) # for parallel processing
library(here) # for tidy file paths
```

## Prepare a subset of data

```{r}
#| eval: false
# Load data
load(here("data/fromMvmtSoc/downsampled_10min_forSocial.Rda")) # produced by the dataPrep script in MvmtSoc project

# Convert to SF
sfdata <- map(downsampled_10min_forSocial, ~st_as_sf(.x, coords = c("location_long", "location_lat"), crs = "WGS84", remove = F))

rm(downsampled_10min_forSocial)

# Put all the seasons together and remove the columns we don't need
sfdata <- purrr::list_rbind(sfdata) %>%
  select(-c(tag_id, sensor_type_id, acceleration_raw_x, acceleration_raw_y, acceleration_raw_z, barometric_height, battery_charge_percent, battery_charging_current, external_temperature, gps_hdop, gps_satellite_count, gps_time_to_fix, import_marked_outlier, light_level, magnetic_field_raw_x, magnetic_field_raw_y, magnetic_field_raw_z, ornitela_transmission_protocol, tag_voltage, update_ts, visible, deployment_id, event_id, sensor_type, tag_local_identifier, location_long.1, location_lat.1, optional, sensor, earliest_date_born, exact_date_of_birth, group_id, individual_id, latest_date_born, local_identifier, marker_id, mates, mortality_date, mortality_latitude, mortality_type, nick_name, offspring, parents, ring_id, siblings, taxon_canonical_name, taxon_detail, number_of_events, number_of_deployments))

# For our own sanity, let's just work with a single season: summer 2023
summer23 <- sfdata %>%
  filter(seasonUnique == "2023_summer")

save(summer23, file = here("data/summer23.Rda"))
rm(sfdata)
```

## Load the Summer 2023 data subset

```{r}
#| include: false
load(here("data/summer23.Rda"))
load(here("data/roosts.Rda"))
roostPolygons <- sf::st_read(here("data/raw/roosts50_kde95_cutOffRegion.kml"))
dim(summer23)
```

## Cut Summer 2023 into different time windows

### Define the time windows

To test how the networks behave over different time intervals, we can prepare a subset of data (summer 2023) cut into different intervals. E.g. 1 day, 5 days, 10 days, 25 days, 50 days.

```{r}
#| include: false
# What are the different time windows we want to test?
timewindows <- c(1, 5, 10, 25, 50)

# A function for cutting a vector of dates (`vec`) into `days`-day intervals
cutdates <- function(vec, days){
  # get min and max dates in the vector
  min <- min(vec)
  max <- max(vec)
  
  # determine how many cutpoints we'll need
  ncutpoints <- ceiling(as.numeric(max-min)/days) + 1
  
  # create the vector of cutpoints
  cutpoints <- seq(from = min, by = days, length.out = ncutpoints)
  
  # cut the dates according to the cutpoints. Intervals will have the format [low, high).
  out <- cut(vec, breaks = cutpoints, include.lowest = T, right = F)
  return(out)
}

# Cut the data into the various intervals
data_cut <- map(timewindows, ~{
  summer23 %>%
    mutate(int = cutdates(dateOnly, .x))
})

length(data_cut) # should be same length as `timewindows` vector

# Okay, now we have the data classified into intervals, time to split each one into a list.
# There is an annoying thing here: when you have an sf object and you run group_by() %>% group_split() on it, the resulting sub-objects do not keep their sf status. They turn into regular data frames. Grrrrr! So I had to add a step to turn each of them back into an sf object.
data_cut <- map(data_cut, ~.x %>% 
                  group_by(int) %>% 
                  group_split() %>%
                  map(., ~sf::st_as_sf(.x, coords = c("location_long", "location_lat"), crs = "WGS84", remove = F)))

length(data_cut) # 5 elements, one for each of the time windows
map_dbl(data_cut, length) # each element has a different number of elements--122 for the 1-day intervals, 25 for the 5-day intervals, etc. etc.

save(data_cut, file = here("data/data_cut.Rda"))
```

Now we we need to do the same cuts for the roost data.

```{r}
#| include: false
roosts_summer23 <- roosts[[9]]

roosts_cut <- map(timewindows, ~{
  roosts_summer23 %>%
    mutate(int = cutdates(roost_date, .x))
})

roosts_cut <- map(roosts_cut, ~.x %>% 
                    group_by(int) %>% 
                    group_split() %>%
                    map(., ~sf::st_as_sf(.x, coords = c("location_long", "location_lat"), crs = "WGS84", remove = F)))

save(roosts_cut, file = here("data/roosts_cut.Rda"))
```

## Get flight, feeding, and roosting edges for each time window

I am using an unholy combination of for loops and `purrr::map()` here, because I find it easier to understand than nested `map` statements (and nested for loops are slower/not easy to parallelize). But they are doing the same thing.

```{r}
#| include: false
# Set up a session for parallel computing, with 10 workers (i.e. can run 10 processes in parallel)
future::plan(future::multisession, workers = 10)

# Initialize lists to hold the outputs of get*Edges.
sris_flight <- vector(mode = "list", length = length(timewindows))
sris_feeding <- vector(mode = "list", length = length(timewindows))
sris_roosting <- vector(mode = "list", length = length(timewindows))

# Run a for loop across all the time windows
for(i in 1:length(timewindows)){
  cat("Working on data split into", timewindows[i], "day intervals\n")
  
  datalist <- data_cut[[i]]
  roostlist <- roosts_cut[[i]]
  cat("Working on flight\n")
  fl <- suppressWarnings(furrr::future_map(datalist, ~{
    library(sf) # have to have this here; it's a quirk of future::map().
    vultureUtils::getFlightEdges(.x, roostPolygons = roostPolygons, distThreshold = 1000, idCol = "Nili_id", return = "sri")
  }, .progress = T))
  
  cat("Working on feeding\n")
  fe <- suppressWarnings(furrr::future_map(datalist, ~{
    library(sf) # have to have this here; it's a quirk of future::map().
    vultureUtils::getFeedingEdges(.x, roostPolygons = roostPolygons, distThreshold = 50, idCol = "Nili_id", return = "sri")
  }, .progress = T))
  
  cat("Working on roosting\n")
  ro <- suppressWarnings(furrr::future_map(roostlist, ~{
    library(sf) # have to have this here; it's a quirk of future::map().
    vultureUtils::getRoostEdges(.x, mode = "polygon",
                                roostPolygons = roostPolygons,
                                return = "sri",
                                latCol = "location_lat",
                                longCol = "location_long",
                                idCol = "Nili_id",
                                dateCol = "roost_date")
    
  }, .progress = T))
  
  # Save the results to their lists
  sris_flight[[i]] <- fl
  sris_feeding[[i]] <- fe
  sris_roosting[[i]] <- ro
  
  # Clean up memory
  rm(list = c("datalist", "roostlist", "fl", "fe", "ro"))
  gc()
}

# Now we have a problem where some of them have length 0 because there were no interactions of that type during the time interval in question. 
# I want to fill in those with a blank data frame with the same format as the other SRI data frames.
# Function to create empty SRI data frames:
fix <- function(data){
  unique_indivs <- unique(data$Nili_id)
  sri <- as.data.frame(expand.grid(unique_indivs, unique_indivs)) %>%
    setNames(c("ID1", "ID2")) %>%
    mutate(sri = 0) %>%
    filter(as.character(ID1) < as.character(ID2))
  return(sri)
}

for(i in 1:length(timewindows)){
  # In order to fix this, we will need access to the sri objects to check (result of the above) as well as the original data
  cat("Fixing results for time window", timewindows[i], "\n")
  
  # Define the current datasets (both sri and original data objects)
  sri_flight <- sris_flight[[i]]
  sri_feeding <- sris_feeding[[i]]
  sri_roosting <- sris_roosting[[i]]
  data_flight <- data_cut[[i]]
  data_feeding <- data_cut[[i]]
  data_roosting <- roosts_cut[[i]]
  
  # For each sri output, check whether it's blank, and if so, fill it in with an empty data frame (i.e. "fix" it). If it's not blank, just leave it as is.
  flight_sris_fixed <- map2(sri_flight, data_flight, ~{
    if(nrow(.x) > 0){out <- .x}
    else{out <- fix(.y)}
    return(out)
  })
  feeding_sris_fixed <- map2(sri_feeding, data_feeding, ~{
    if(nrow(.x) > 0){out <- .x}
    else{out <- fix(.y)}
    return(out)
  })
  roosting_sris_fixed <- map2(sri_roosting, data_roosting, ~{
    if(nrow(.x) > 0){out <- .x}
    else{out <- fix(.y)}
    return(out)
  })
  
  # Save the results to their lists (overwriting what was there before)
  sris_flight[[i]] <- flight_sris_fixed
  sris_feeding[[i]] <- feeding_sris_fixed
  sris_roosting[[i]] <- roosting_sris_fixed
  
  # Clean up memory
  rm(list = c("sri_feeding", "sri_flight", "sri_roosting", "data_flight", "data_feeding", "data_roosting"))
  gc()
}
```

## Make the network graphs

```{r}
#| include: false
# Create lists to store the network graphs
graphs_flight <- vector(mode = "list", length = length(timewindows))
graphs_feeding <- vector(mode = "list", length = length(timewindows))
graphs_roosting <- vector(mode = "list", length = length(timewindows))

# Set up a "plan" to run this code in parallel, so it will go much faster
future::plan(future::multisession, workers = 10)

# For each time window, loop through the edge lists and turn them into graphs
for(i in 1:length(timewindows)){
  flight <- sris_flight[[i]]
  feeding <- sris_feeding[[i]]
  roosting <- sris_roosting[[i]]
  flightgraphs <- furrr::future_map(flight, ~vultureUtils::makeGraph(mode = "sri", data = .x, weighted = T),
                                    .progress = T)
  feedinggraphs <- furrr::future_map(feeding, ~vultureUtils::makeGraph(mode = "sri", data = .x, weighted = T),
                                     .progress = T)
  roostinggraphs <- furrr::future_map(roosting, ~vultureUtils::makeGraph(mode = "sri", data = .x, weighted = T), .progress = T)
  
  # Fill the lists with the created graphs
  graphs_flight[[i]] <- flightgraphs
  graphs_feeding[[i]] <- feedinggraphs
  graphs_roosting[[i]] <- roostinggraphs
  
  # Clean up memory
  rm(flightgraphs)
  rm(feedinggraphs)
  rm(roostinggraphs)
}

# Save the graphs to files
save(graphs_flight, file = here("data/graphs_flight.Rda"))
save(graphs_feeding, file = here("data/graphs_feeding.Rda"))
save(graphs_roosting, file = here("data/graphs_roosting.Rda"))
```

## Calculate individual-level metrics

In order to properly label the metrics in the data frame, we need to know which interval they're associated with. Let's retrieve the interval names from the original data.

```{r}
#| include: false
brks <- map(data_cut, ~map_chr(.x, ~as.character(.x$int[1])))
brks_roosts <- map(roosts_cut, ~map_chr(.x, ~as.character(.x$int[1])))
identical(brks, brks_roosts) # FALSE--this is a problem. Must mean we were missing some roost data. #XXX investigate...
```

```{r}
#| include: false
# Function to get degree and strength
getmetrics <- function(graph, interval, type, days){
  if(length(graph) > 0){
      metrics <- data.frame(degree = igraph::degree(graph),
                    strength = igraph::strength(graph),
                    Nili_id = names(igraph::degree(graph)),
                    int = interval,
                    n = length(V(graph)),
                    type = type,
                    ndays = days)
  }else{
    metrics <- data.frame(degree = NA, strength = NA, 
                          Nili_id = NA, int = interval, 
                          n = 0, type = type, ndays = days)
  }

  return(metrics)
}

# Initialize lists to hold the metrics
metrics_flight_indiv <- vector(mode = "list", length = length(timewindows))
metrics_feeding_indiv <- vector(mode = "list", length = length(timewindows))
metrics_roosting_indiv <- vector(mode = "list", length = length(timewindows))

# Calculate metrics for each graph, using the getmetrics function defined above.
for(i in 1:length(timewindows)){
  metrics_flight_indiv[[i]] <- map2(graphs_flight[[i]], brks[[i]], ~{
    getmetrics(graph = .x, interval = .y, type = "flight", days = timewindows[i])
  })
  metrics_feeding_indiv[[i]] <- map2(graphs_feeding[[i]], brks[[i]], ~{
    getmetrics(.x, .y, "feeding", timewindows[i])
  })
  metrics_roosting_indiv[[i]] <- map2(graphs_roosting[[i]], brks_roosts[[i]], ~{
    getmetrics(.x, .y, "roosting", timewindows[i])
  })
}

# Smoosh the lists down into data frames instead (so now, instead of a list of lists, we will have a list of data frames)
metrics_flight_indiv_df <- map(metrics_flight_indiv, ~purrr::list_rbind(.x))
metrics_feeding_indiv_df <- map(metrics_feeding_indiv, ~purrr::list_rbind(.x))
metrics_roosting_indiv_df <- map(metrics_roosting_indiv, ~purrr::list_rbind(.x))

# smoosh the lists further into data frames (one data frame for each social situation), and bind all the situations together into a single data frame. We can do this because we specified "type" in the for loop above, so all the data is already labeled.
metrics_indiv <- bind_rows(purrr::list_rbind(metrics_flight_indiv_df), 
                     purrr::list_rbind(metrics_feeding_indiv_df), 
                     purrr::list_rbind(metrics_roosting_indiv_df))
row.names(metrics_indiv) <- NULL
metrics_indiv <- metrics_indiv %>%
  group_by(ndays, int) %>%
  mutate(normDegree = degree/(n-1),
         normStrength = strength/sum(strength, na.rm = T))
save(metrics_indiv, file = here("data/metrics_indiv.Rda"))
```

## Attach metrics to graphs

I'm going to use the structure called `tbl_graph` from the `tidygraph` package, because it makes attaching node or edge characteristics much easier than igraph (using the tidyverse framework).

```{r}
#| include: false
# Create lists to store the tbl_graph objects
graphs_flight_tbl <- vector(mode = "list", length = length(timewindows))
graphs_feeding_tbl <- vector(mode = "list", length = length(timewindows))
graphs_roosting_tbl <- vector(mode = "list", length = length(timewindows))

# Fill the lists: convert each graph to a tbl_graph, and then join the metrics calculated above.
for(i in 1:length(timewindows)){
  fl_tbl <- map(graphs_flight[[i]], ~as_tbl_graph(.x))
  fe_tbl <- map(graphs_feeding[[i]], ~as_tbl_graph(.x))
  ro_tbl <- map(graphs_roosting[[i]], ~as_tbl_graph(.x))
  
  graphs_flight_tbl[[i]] <- map2(fl_tbl, metrics_flight_indiv[[i]], ~{
    .x %>% activate(nodes) %>%
      left_join(.y, by = c("name" = "Nili_id"))
  })
  graphs_feeding_tbl[[i]] <- map2(fe_tbl, metrics_feeding_indiv[[i]], ~{
    .x %>% activate(nodes) %>%
      left_join(.y, by = c("name" = "Nili_id"))
  })
  graphs_roosting_tbl[[i]] <- map2(ro_tbl, metrics_roosting_indiv[[i]], ~{
    .x %>% activate(nodes) %>%
      left_join(.y, by = c("name" = "Nili_id"))
  })
}

# Save the tbl_graphs with attached metrics to files
save(graphs_flight_tbl, file = here("data/graphs_flight_tbl.Rda"))
save(graphs_feeding_tbl, file = here("data/graphs_feeding_tbl.Rda"))
save(graphs_roosting_tbl, file = here("data/graphs_roosting_tbl.Rda"))
```

## Make some visualizations

```{r}
#| include: false
load(here("data/metrics_indiv.Rda"))
```

Taking a look at some metrics: how does individual degree differ by time window?

```{r}
metrics_indiv %>%
  ggplot(aes(x = ndays, y = normDegree, col = type))+
  geom_jitter(alpha = 0.1, width = 0.6)+
  theme_classic()+
  facet_wrap(~type)+
  ylab("Degree (normalized)")+
  xlab("Time window (days)")+
  theme(legend.position = "none")+
  NULL
```

What about individual normalized strength?

```{r}
metrics_indiv %>%
  ggplot(aes(x = ndays, y = normStrength, col = type))+
  geom_jitter(alpha = 0.1, width = 0.6)+
  theme_classic()+
  facet_wrap(~type)+
  ylab("Strength (normalized)")+
  xlab("Time window (days)")+
  theme(legend.position = "none")+
  NULL
```

Okay interesting. What about mean degree or strength across the whole population? (We will still have different numbers of dots for each time window–maybe only one or two for the highest time window, and many for the 1-day window.

```{r}
metrics_indiv %>%
  group_by(type, ndays, int) %>%
  summarize(mndeg = mean(normDegree)) %>%
  ggplot(aes(x = ndays, y = mndeg, col = type))+
  geom_point(alpha = 0.5, size = 2)+
  theme_classic()+
  facet_wrap(~type)+
  ylab("Mean degree (normalized)")+
  xlab("Time window (days)")+
  theme(legend.position = "none")+
  NULL

metrics_indiv %>%
  group_by(type, ndays, int) %>%
  summarize(mnstr = mean(normStrength)) %>%
  ggplot(aes(x = ndays, y = mnstr, col = type))+
  geom_point(alpha = 0.5, size = 2)+
  theme_classic()+
  facet_wrap(~type)+
  ylab("Mean strength (normalized)")+
  xlab("Time window (days)")+
  theme(legend.position = "none")+
  NULL
```

What about degree/strength per time period? Let's look at how this changes for 5 random individuals in the population.

```{r}
set.seed(3)
random_vultures <- sample(unique(metrics_indiv$Nili_id), 
                          size = 5, replace = FALSE)
metrics_indiv <- metrics_indiv %>%
  mutate(selected = ifelse(Nili_id %in% random_vultures, TRUE, FALSE))

metrics_indiv %>%
  filter(selected == TRUE) %>%
  ggplot(aes(x = lubridate::ymd(int), y = normDegree, group = interaction(Nili_id, type)))+
  geom_line(aes(col = Nili_id), alpha = 0.7)+
  #facet_grid(rows = vars(ndays), cols = vars(type))+
  theme_classic()+
  theme(legend.position = "none")+
  ylab("Degree (normalized)")+
  xlab("Date")+
  ggh4x::facet_nested("Time window (days)" + ndays ~ "Situation" + type)+
  theme()
```

This plot definitely suggests that we have different temporal scales going on!

How do network-level metrics change over time? (I have not calculated network-level metrics such as density and modularity yet–could go back and do that. For now, I'm going to use mean mean degree/mean mean strength as measures).

```{r}
#| echo: false
#| message: false
metrics_net <- metrics_indiv %>%
  group_by(ndays, int, type, n) %>%
  summarize(mnnormdeg = mean(normDegree),
            mnnormstr = mean(normStrength)) %>%
  ungroup() %>%
  mutate(int = lubridate::ymd(int))

metrics_net %>%
  ggplot(aes(x = int, y = mnnormdeg, col = factor(ndays)))+
  geom_point()+
  geom_line()+
  facet_wrap(~type, ncol = 1, scales = "free")+
  theme_classic()+
  ylab("Mean degree (normalized)")+
  xlab("Date")

metrics_net %>%
  group_by(ndays, type) %>%
  summarize(mn_mnnormdeg = mean(mnnormdeg)) %>%
  ggplot(aes(x = ndays, y = mn_mnnormdeg, col = type))+
  geom_point(size = 5)+
  geom_line(linewidth = 2)+
  ylab("Mean degree (normalized)")+
  xlab("Time window (days)")+
  theme_classic()
```
